# Лабораторная работа №3
# Создание бенчмарка для различных библиотек для работы с базами данных на python

![image](https://github.com/neros-ch/database_course_benchmark/assets/60364024/5994d651-b4ed-4012-b21f-f40effde4906)

*В качестве результатов измерений были взяты медианные значения среди 15 повторений каждого запроса.*

# Производительность

## Postgres
Самой медленной библиотекой оказалась Postgres. Я считаю что к этому привели несколько причин. Во-первых, это единственная библиотека, связь с которой устанавливалась хоть и внутри одного ПК, но всё же через локальную сеть. Во вторых, бэкенд сервер размещён в docker контейнере, что тоже накладывает свои ограничения на производительность.

![image](https://github.com/neros-ch/database_course_benchmark/assets/60364024/a47f1ffe-3592-43cd-b80d-8d93096dfd61)

## SQLite и SQLAlchemy
Следующее место между собой разделили библиотеки SQLite и SQLAlchemy. Это вполне ожидаемый результат, ведь в этом бенчмарке в качестве бэкенда SQLAlchemy использовала как раз таки SQLite. По большей части SQLAlchemy была немного медленнее. Я бы это объяснил тем что "алхимия" хоть и обеспечивает удобную интеграцию в язык python посредством ООП (подтверждаю двухлетним опытом тесного взаимодействия с ней), но всё же теряет некоторую производительность из-за этого.

![image](https://github.com/neros-ch/database_course_benchmark/assets/60364024/0896611f-754d-4b1b-841c-d6b6edb6bd0f)
![image](https://github.com/neros-ch/database_course_benchmark/assets/60364024/2c922cbf-c9df-4c22-9417-2a8f9272932a)

## Pandas
Второе место по скорости заняла библиотека Pandas. В моем бенчмарке она была использована сама по себе, то есть без привязки к базе данных. Такой вариант использования привел к ускорению более чем в два раза, по сравнению с ранними вариантами бенчмарка, где была привязка к SQLite, хранящейся в ОЗУ. Первые два запроса выполнились практически мгновенно, а последующие - чуть дольше 1,5 секунды. Я считаю, что скорее всего это не могло быть вызвано нагруженностью запроса, так как разница слишком значительная, а стало следствием использованием внутри библиотеки какого-то медленного участка кода, который задействуется только в 3 и 4 запросах.

![image](https://github.com/neros-ch/database_course_benchmark/assets/60364024/4077dbc4-18f0-4ca6-afcb-7b7a57784034)

## DuckDB
Почетное первое место заняла библиотека DuckDB со своими феноменальными результатами менее 4 сотых секунды, когда у конкурентов (работающих с бд) результат почти не опускался ниже секунды. Все библиотеки, за исключением Postgres, хранили свои данные в оперативной памяти. Поэтому такой прирост производительности обеспечен именно особенностями алгоритмов работы с данными внутри DuckDB.

![image](https://github.com/neros-ch/database_course_benchmark/assets/60364024/23e6e6d1-94e2-454e-b305-591f9adb8d95)

# Удобство использования

В рамках написания бенчмарка самой неудобной показалась библиотека SQLAlchemy. В основном такое ощущение сложилось из-за массивных запросов, которые было очень непривычно писать, используя исключительно встроенные для этого функции. Как по мне, намного удобнее работать с этой библиотекой если по максимуму использовать взаимодействие объектов, описанных классами(моделями) и добавить CRUD. Например, такое удобно использовать в бизнес процессах на различных предприятиях, например промышленных, где есть большое количество объектов, которые взаимодействуют между собой и в итоге выстраивать бизнес-логику получается намного быстрее и комфортнее именно при помощи взаимодействия конкретных объектов. В рамках реального продакшена SQLAlchemy является достаточно мощным инструментом, особенно в связке со "взрослыми" базами данных, такими как Postgres и MySQL.

Pandas я бы поставил на второе место по удобству. Всё-таки у этой библиотеки в основном встречаются другие задачи, а не написание SQL-подобных запросов.

Первое место по удобству занимают сразу все три оставшиеся библиотеки, так как взаимодействие с ними практически одинаковое. Разве что расстроил только SQLite отсутствием 
функции extract, из-за чего пришлось писать запросы специально для этой библиотеки.

# Инструкция по использованию бенчмарка
Основными программными файлами бенчмарка являются main.py (запуск бенчмарка) и config.py (настройка конфигурации). Остальные вспомогательные файлы лежат в директории app.

Список необходимых внешних библиотек лежит в файле requirements.txt.

Предполагается, что датасет будет расположен в папке datasets, но это можно изменить в config файле.

Для работы с Postgres требуется запущенный Postgres сервер, в нашем случае - в docker контейнере.

В датасете был вручную изменен заголовок последнего столбца с Airport_fee на Airport_fee2, так как исходное наименование вызывало конфликт со столбцом airport_fee почти во всех библиотеках.
